{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "06c1e258a470a687113bfba03f207c092b27379067ada2d83b8b31269ab641fe"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Pre-trained models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Why spend time designing, coding or training models yourself, when someone else has already done it for you?!\n",
    "\n",
    "PyTorch's library `torchvision` has a `models` module which contains functionality for easily downloading state of the art models.\n",
    "\n",
    "See the documentation for this module [here](https://pytorch.org/docs/stable/torchvision/models.html)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, models\n",
    "\n",
    "model = models.detection.vgg11(pretrained=True)"
   ]
  },
  {
   "source": [
    "We can use these models \"off the shelf\", without the need to train them - just like we use our usual models that we build and train ourself.\n",
    "\n",
    "If for some reason we didn't want the pretrained weights, we could also set `pretrained=False` and just get back the model architecture.\n",
    "\n",
    "Let's load in an image to pass through our model to make a prediction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "img = Image.open('plane.jpg')\n",
    "img.show()"
   ]
  },
  {
   "source": [
    "## Preparing your input\n",
    "\n",
    "\n",
    "### NORMALISE YOUR input\n",
    "\n",
    "The classification models have all been trained on the [ImageNet](http://www.image-net.org/) dataset.\n",
    "\n",
    "During this training procedure, each example was normalised before being passed to the model.\n",
    "This means that our model is trained to process normalised examples. \n",
    "An unnormalised example will look very different to a normalised example, and the model will not know how to process it.\n",
    "If you forget to normalise each input, your predictions will suck.\n",
    "\n",
    "We do not need to compute the normalisation parameters for the ImageNet dataset, they're commonly found in the documentation and other code.\n",
    "These are the means and standard deviations of the pixel intensities in the red, green and blue channels of each input.\n",
    "PyTorch has a transform for easily applying this normalisation.\n",
    "\n",
    "### Resize your input \n",
    "All of the classification models consist of convolutional layers whos output is flattened and passed through linear layers. \n",
    "The linear layers require a fixed size output. \n",
    "The output of the conv layers changes if its input size changes, so we'll need to resize (warp) each input image to the expected size (which depends on the model).\n",
    "\n",
    "We'll compose these transforms into a single transform as shown below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "img = transform(img)"
   ]
  },
  {
   "source": [
    "What's the size of any input to a torch model?\n",
    "\n",
    "Let me phrase that in a way that should make the answer more obvious...\n",
    "\n",
    "What's the first dimension in any input to a torch model?\n",
    "\n",
    "THE BATCH DIMENSION\n",
    "\n",
    "The only thing our input image is missing now is the batch dimension.\n",
    "We can add that by \"unsqueezing\" a the 1st dimension to add in a new dimension of size 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "img = img.unsqueeze(0)\n",
    "print(img.shape)"
   ]
  },
  {
   "source": [
    "Now we can pass our input through the model. \n",
    "Before we do that though, we need to make sure all of the layers of our model are in evaluation mode. This is so that if any of them behave differently between training and evaluation, we specify that they are now being used for evaluation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(img)\n",
    "print(pred)"
   ]
  },
  {
   "source": [
    "When using any of the classification models, the output is a vector of logits (what we usually input to a softmax function to produce a probability distribution over classifications).\n",
    "To find the name of the acutal class predicted, find the argmax of these logits.\n",
    "This will be an integer index which represents a class.\n",
    "To see the mapping between index and class, see [here](https://gist.github.com/ageitgey/4e1342c10a71981d0b491e1b8227328b)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(pred.shape)\n",
    "pred = torch.argmax(pred, dim=1)\n",
    "print(pred)\n"
   ]
  },
  {
   "source": [
    "Try out some of the other classification models. Then try out some of the models for more complicated tasks like segmentation. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and DataLoaders\n",
    "\n",
    "PyTorch provides a way to create your own data via [`torch.utils.data`](https://pytorch.org/docs/stable/data.html) module.\n",
    "\n",
    "It allows us to:\n",
    "- Create custom datasets (finite or infinite)\n",
    "- Quickly load data in batches using multiple processes\n",
    "- Pin data to GPU memory for faster transfers\n",
    "\n",
    "## Map-style datasets\n",
    "\n",
    "Those are the most common datasets and have a really simple structure:\n",
    "- Create a class by inheriting from [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\n",
    "- Override `__init__` (__optionally, if needed__)\n",
    "- Define `__getitem__(self, index)` method (__responsible for obtaining SINGLE sample__)\n",
    "- Define `__len__(self)` method (__how many samples are there in total__)\n",
    "\n",
    "Let's see how this looks in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, l: typing.List[typing.Any]):\n",
    "        self.l = l\n",
    "\n",
    "    # Not dependent on index\n",
    "    def __getitem__(self, index):\n",
    "        return self.l[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.l)\n",
    "\n",
    "\n",
    "dataset = DummyDataset([0, 1, 2, 3, 4, 5])\n",
    "len(dataset), dataset[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Create a dataset with `X` data and `y` labels by inheriting from `torch.utils.data.Dataset` (name it `Dataset`).\n",
    "- Code setup in `__init__(X, y)` (verify that `X` and `y` are of equal length (you can use [`assert`](https://stackoverflow.com/questions/5142418/what-is-the-use-of-assert-in-python) for that)\n",
    "- In `__getitem__` return `tuple` containing sample and it's respective label defined by `index`\n",
    "- In `__len__` return how many samples are contained in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders\n",
    "\n",
    "Please notice, our `torch.utils.data.Dataset` __returns single element__.\n",
    "\n",
    "> In deep learning, we use batches of data (as much as we can fit onto GPU usually)\n",
    "\n",
    "Because of that, PyTorch provides another abstraction: `torch.utils.data.DataLoader`:\n",
    "\n",
    "> DataLoader batches our data so it is easily consumed by neural networks\n",
    "\n",
    "### Automated batching\n",
    "\n",
    "Usually, we will go for automated batching which is really simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(torch.randn(300, 10), torch.randint(0, 5, size=(300,)))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)\n",
    "\n",
    "for (X, y) in dataloader:\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More about DataLoader\n",
    "\n",
    "[`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) has a lot of arguments (all of them optional except providing `Dataset` instance), most important ones being:\n",
    "- `batch_size: int` - we've seen it above\n",
    "- `shuffle: bool` - whether dataset should be shuffled before each iteration\n",
    "- `num_workers: int` - how many workers are used for data loading\n",
    "- `pin_memory: bool` - whether tensors should be loaded into pinned memory regions which may improve tensor transfer to GPU\n",
    "\n",
    "> `DataLoader` can only be iterated over, no random access is provided\n",
    "\n",
    "> Many of `DataLoader` arguments are mutually exclusive and there is more than one way to specify certain things. __Always go for the easiest and shortest option if possible__\n",
    "\n",
    "## num_workers\n",
    "\n",
    "> `num_workers` specifies how many processes in parallel will be used to load data\n",
    "\n",
    "### Not enough workers\n",
    "\n",
    "- Our __pipeline__ will wait for data while neural network sits idle\n",
    "- Underutilization\n",
    "- Longer training times\n",
    "\n",
    "### Too many workers\n",
    "\n",
    "- Likely to crash in extreme cases\n",
    "- May crash after a while (importance of model saving)\n",
    "- Might make the whole system laggy\n",
    "\n",
    "### How to find correct amount of workers?\n",
    "\n",
    "- Start with number of available cores divided by two (`multiprocessing.cpu_count()`), usually is a good default\n",
    "- Test a little larger, in case of crash continue division by two and repeat\n",
    "\n",
    "> Details about multiple workers are located [here](https://pytorch.org/docs/stable/data.html#multi-process-data-loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler\n",
    "\n",
    "> Sampler __generates indices__ which are used to to __get data from `Dataset` contained in `DataLoader`__\n",
    "\n",
    "This means, we can control __how__ our dataset is actually sampled, which allows us to:\n",
    "- perform over/undersampling\n",
    "- sample some examples more often, because:\n",
    "    - they are more important\n",
    "    - they are harder for neural network and should be seen more often\n",
    "    \n",
    "When we specify `shuffle=True` actually an instance of [`torch.utils.data.RandomSampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.RandomSampler) is implicitly created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision\n",
    "\n",
    "`torchvision` is part of PyTorch project and described as:\n",
    "\n",
    "> The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
    "\n",
    "It has to be installed separately (though it's advised to download it with PyTorch).\n",
    "\n",
    "> We will focus on MNIST dataset so you can see whole PyTorch data loading pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    # Training dataset as torch.utils.data.Dataset instance\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root=tmp_dir,  # where data is stored\n",
    "        transform=torchvision.transforms.ToTensor(),  # how each sample will be transformed\n",
    "        train=True,  # we want training data\n",
    "        download=True,  # should i download it if it's not already here?\n",
    "    )\n",
    "\n",
    "    # Test dataset as torch.utils.data.Dataset instance\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root=tmp_dir,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "        train=False,\n",
    "    )\n",
    "    \n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_dataset[0][0]\n",
    "print(x.shape)\n",
    "plt.imshow(x.squeeze().numpy(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n",
    "\n",
    "Sometimes, we might need to split the data (usually to get validation dataset).\n",
    "\n",
    "PyTorch provides [`torch.utils.data.random_split`](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split) for those cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [50000, 10000]\n",
    ")  # split into 50K training & 10K validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders\n",
    "\n",
    "Below, dataloaders are created as a dictionary; you may sometimes see this approach:\n",
    "- Pros:\n",
    "    - easier to read (instead of `training_dataloader`)\n",
    "    - easier to use\n",
    "- Cons:\n",
    "    - still a lot of repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    ),\n",
    "    \"validation\": torch.utils.data.DataLoader(\n",
    "        validation_dataset, batch_size=BATCH_SIZE, pin_memory=torch.cuda.is_available()\n",
    "    ),\n",
    "    \"test\": torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=BATCH_SIZE, pin_memory=torch.cuda.is_available()\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Add code to a `Runner` class which will wrap training of provided model\n",
    "(as always, add your code where `...` are located):\n",
    "\n",
    "- `evaluate` method:\n",
    "    - Iterate over dataloader\n",
    "    - Cast both `X` and `y` to `self.device` (see previous notebook if needed)\n",
    "    - Get outputs from model\n",
    "    - Pass `outputs` and `y` to `self.feed_metrics` function\n",
    "    \n",
    "- `train` method:\n",
    "    - Iterate over dataloader\n",
    "    - Cast both `X` and `y` to `self.device` (see previous notebook if needed)\n",
    "    - Get outputs from model\n",
    "    - Calculate loss using `self.criterion`\n",
    "    - Backpropagate through graph\n",
    "    - Take step of `self.optimizer` and zero it's gradient using `zero_grad`\n",
    "    - Pass `outputs` and `y` to `self.feed_metrics` function\n",
    "    \n",
    "After that fill `Accuracy`'s `forward` method which calculates __multiclass accuracy__ from outputted `logits` and integer-encoded labels. You should return a single scalar value.\n",
    "\n",
    "__Tips:__\n",
    "- `torch.argmax`\n",
    "- cast to `float` after comparison\n",
    "- __remember to take `torch.mean` of the value__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Runner:\n",
    "    model: torch.nn.Module\n",
    "    criterion: typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n",
    "    optimizer: torch.optim.Optimizer\n",
    "    device: torch.device\n",
    "    metrics: typing.Iterable[\n",
    "        typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n",
    "    ]\n",
    "\n",
    "    def feed_metrics(self, outputs, y):\n",
    "        for metric in self.metrics:\n",
    "            metric(outputs, y)\n",
    "\n",
    "    def print_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            print(f\"{metric.__class__.__name__}: {metric.evaluate()}\")\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            ...\n",
    "        self.print_metrics()\n",
    "\n",
    "    def train(self, dataloader):\n",
    "        self.model.train()\n",
    "        ...\n",
    "        self.print_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self):\n",
    "        self.cache = 0\n",
    "        self.i = 0\n",
    "\n",
    "    def __call__(self, logits, labels):\n",
    "        self.i += 1\n",
    "        self.cache += self.forward(logits.detach(), labels)\n",
    "\n",
    "    def evaluate(self):\n",
    "        result = self.cache / self.i\n",
    "        self.cache = 0\n",
    "        self.i = 0\n",
    "        return result\n",
    "\n",
    "\n",
    "class CrossEntropyLoss(Metric):\n",
    "    def forward(self, logits, labels):\n",
    "        return torch.nn.functional.cross_entropy(logits, labels, reduction=\"mean\")\n",
    "\n",
    "class Accuracy(Metric):\n",
    "    def forward(self, logits, labels):\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Let's see our first neural network classifier of MNIST digits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, padding=1),\n",
    "    torchvision.models.resnet18(num_classes=10),\n",
    ").to(device)\n",
    "runner = Runner(\n",
    "    model,\n",
    "    torch.nn.CrossEntropyLoss(),\n",
    "    torch.optim.Adam(model.parameters(), lr=3e-4),\n",
    "    device,\n",
    "    [Accuracy(), CrossEntropyLoss()],\n",
    ")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"===================== EPOCH {epoch} ===================\")\n",
    "    print(f\"=================== TRAINING ====================\")\n",
    "    runner.train(dataloaders[\"train\"])\n",
    "    print(f\"================== VALIDATION ===================\")\n",
    "    runner.evaluate(dataloaders[\"validation\"])\n",
    "    print(f\"===================== TEST ======================\")\n",
    "    runner.evaluate(dataloaders[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- In PyTorch we create datasets by inheriting from `torch.utils.data.Dataset`:\n",
    "    - those return a single item during each iteration\n",
    "    - really simple & lightweight abstraction\n",
    "- `torch.utils.DataLoader` takes care of:\n",
    "    - batching\n",
    "    - shuffling\n",
    "    - speed ups when loading data\n",
    "- __You should always provide your dataset instance to `DataLoader`!__\n",
    "- `torchvision` is part of PyTorch project and provides:\n",
    "    - datasets\n",
    "    - transformations\n",
    "    - vision related models\n",
    "- Default `pytorch` requires a lot of boilerplate code but is a battle-tested approach to training neural networks\n",
    "\n",
    "## Challenges\n",
    "\n",
    "- what are [IterableDatasets](https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset)? Where those might be used?\n",
    "- read more about [Memory Pinning](https://pytorch.org/docs/stable/data.html#memory-pinning)\n",
    "- check out third party module [torchdata](https://github.com/szymonmaszke/torchdata) for other ways to handle caching and data transformations of PyTorch's `Dataset`\n",
    "- go over PyTorch's [data documentation](https://pytorch.org/docs/stable/data.html) and learn a little more about the details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

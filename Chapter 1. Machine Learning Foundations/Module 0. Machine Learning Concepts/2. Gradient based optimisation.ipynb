{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient based optimisation\n",
    "\n",
    "## Prerequisites\n",
    "- [Calculus primer]\n",
    "- [Intro to machine learning]()\n",
    "\n",
    "## Learning objectives\n",
    "- Understand the concepts behind gradient based optimisation and learning\n",
    "- Implement the stochastic gradient descent (SGD) algorithm from scratch in Python (develop your Python programming skills)\n",
    "\n",
    "## Intro\n",
    "\n",
    "Previously, we saw how we could optimise parameters of our models using random search. This technique had some fundamental flaws though...\n",
    "- we had to specify the range which we would search for parameter values within, and this might not contain the optimal parameter values (e.g. if we search all parameters from 1 to 10, but the ideal parameter value is 15, then we will never find an optimal parameterisation)\n",
    "- we don't use information about a current parameterisation as a heuristic for where to search next. We simply take either a totally random value (random search) or a predetermined value (grid search)\n",
    "- to maintain the same resolution of search, the number of datapoints that you need scales exponentially with the number of parameters. This is very bad (the neural networks which we will use soon can easily have millions of parameters).\n",
    "\n",
    "This notebook will walk through how we can use **gradient based optimisation** as another technique to find model parameterisations that perform well.\n",
    "\n",
    "To get your mind running, gradient based optimisation looks a bit like this:\n",
    "\n",
    "![](images/gradient_descent_intuition.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is gradient based optimisation all about?\n",
    "\n",
    "Our loss is just a mathematical function that depends on the parameters of our model (for example, we used the mean squared error (MSE) loss function in the previous notebook).\n",
    "We would like to move our parameters to the point where loss is minimised.\n",
    "\n",
    "If we were to evaluate the value of our loss for every possible different parameterisation of our model, we would produce a **loss surface**. \n",
    "We would like to find the lowest point on this surface. \n",
    "At this point it will have a gradient (steepness) of zero with respect to the parameters.\n",
    "\n",
    "As our parameters move away from that minima in some direction, the gradient will increase in that direction.\n",
    "To get back to the minima, we should hence move our weights in the opposite direction.\n",
    "This tells us that wherever we are, we can decrease the current value of the loss by moving in the opposite \n",
    "direction to the gradient. This is at the core of gradient based optimisation.\n",
    "\n",
    "![](./images/grad-based-optim.jpg)\n",
    "\n",
    "## Numerical example\n",
    "\n",
    "Below is an example that shows the direction to shift a parameter $W$, initialised as $w=4$, for a surface given by $L=(W-2)^2$. \n",
    "At this point on the surface, the gradient of the loss with respect to this parameter is positive, so we should shift it in the negative direction to push it closer the the optima.\n",
    "\n",
    "![](images/sgd_numerical_example.jpg)\n",
    "\n",
    "Below is a more complex potential loss surface which varies with more than just one parameter (vertical axis represents loss value, others represent parameter values).\n",
    "\n",
    "<img style=\"height: 200px\" src='./images/comp-loss-surface.png'/>\n",
    "\n",
    "**Note: because gradient based optimisation depends on us computing the gradient of the loss function, our loss function and model must be fully differentiable (they must be a smooth, continuous function).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WORRY ABOUT THIS CELL, IT JUST SETS SOME STUFF UP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import get_regression_data, visualise_regression_data\n",
    "\n",
    "X, Y = get_regression_data()\n",
    "visualise_regression_data(X, Y)\n",
    "\n",
    "# DEFINE MEAN SQUARED ERROR LOSS FUNCTION\n",
    "def L(y_hat, labels):\n",
    "    errors = y_hat - labels # calculate errors\n",
    "    squared_errors = np.square(errors) # square errors\n",
    "    mean_squared_error = np.sum(squared_errors) / (len(y_hat)) # calculate mean \n",
    "    return mean_squared_error # return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "Gradient descent is an iterative, gradient based optimisation technique. \n",
    "That is, it is a technique for finding the minima (or maxima) of a function, and it does so by iteratively moving the parameters downhill, in the direction of the gradient of the surface.\n",
    "\n",
    "### Gradient descent algorithm\n",
    "- randomly initialise model parameters\n",
    "- while not converged:\n",
    "    - Calculate the cost of this parameterisation (by evaluating how it performs on some examples) and the derivative of our cost with respect to (w.r.t) each parameter. This derivative is a vector that points in the direction of steepest ascent (the gradient of the loss surface for this parameterisation). The elements of the vector are \n",
    "    - Update each parameter value by taking a step in the opposite direction to this gradient vector. \n",
    "\n",
    "![](images/gradient_descent_intuition.jpg)\n",
    "\n",
    "In our case, the function that we want to minimise is our loss function (how bad our model is doing).\n",
    "We can get a differentiable expression for this loss surface:\n",
    "\n",
    "## $$L = \\mathbb{E}_{x~p_{train}(x)} [(\\hat{y} - y)^2] = \\mathbb{E}_{x~p_{train}(x)} [(XW + b - y)^2]$$\n",
    "\n",
    "## $$\\frac{\\partial L}{\\partial w} = \\frac{2}{m} \\Sigma_{i=1}^m (x^{(i)}W - y^{(i)})x^{(i)}$$\n",
    "\n",
    "### The learning rate, $\\alpha$\n",
    "\n",
    "We will update our parameters by shifting them in the opposite direction to the gradient. But by what amount should we shift them in that direction?\n",
    "\n",
    "If the step size were some constant value, then our model might need to adjust its weights by some value smaller than this to reach a nearby minima. \n",
    "\n",
    "We know that the gradient at a minima is zero, and at this point we want our parameters to be moved with a step size of zero - so that they remain where they are, at the minima. So let's consider the weights of the model being updated by a step size proportional to the gradient. We call the proportionality constant the **learning rate**, and denote it as $\\alpha$.\n",
    "\n",
    "If the step size were directly equal to the gradient ($\\alpha=1$), gradient descent can fail to converge because the steps are too large (the same problem hence occurs if the learning rate is too large)\n",
    "\n",
    "![title](images/high-lr.jpg)\n",
    "\n",
    "So we include the learning rate to scale down the size of the steps. The learning rate should most likely be less than 1.\n",
    "\n",
    "If the learning rate is too low, then our model can take too long (too many gradient descent iterations) to converge\n",
    "\n",
    "![title](images/low-lr.jpg)\n",
    "\n",
    "You should play around with the learning rate and adjust it until your model converges.\n",
    "\n",
    "![title](images/convergence.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OH NO WHAT ABOUT LOCAL OPTIMA?\n",
    "\n",
    "Don't stress too much.\n",
    "\n",
    "Yes, in the case where we are trying to minimise a function with respect to 1 or 2 parameters, gradient descent is prone to getting stuck in local optima.\n",
    "\n",
    "But most of the models that are useful in practice depend on many more parameters (neural networks can easily have millions).\n",
    "And as the number of parameters increase, it becomes exponentially unlikely that any parameterisation is at a minima, but is rather a saddle point, and so there is still an indication of how to improve.\n",
    "\n",
    "Furthermore, in practice we often find that we don't need to find a global optima.\n",
    "Local optima can be good enough to reach our required performance.\n",
    "\n",
    "On top of this, we can attempt to counter getting stuck in local optima by using different optimisation algorithms, such as [gradient descent with (Nesterov) momentum](https://distill.pub/2017/momentum/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate gradient descent\n",
    "\n",
    "The diagrams shown above visualise how a single parameter affects the loss. A model with multiple parameters (such as a weight and a bias, or multiple weights) would be optimised in the same way - we would just have more of these functions. We can think of each of the graphs as a cross section through a **loss surface**. A loss surface is shown below which visualises how the criterion of a model might vary with both parameters.\n",
    "\n",
    "# $$L = w_1^4 + w_2^2$$\n",
    "\n",
    "<img style=\"height: 300px; transform: translateX(50%);left: 0\" src='images/x2x4.png'/>\n",
    "\n",
    "![](images/multivariate_sgd.jpg)\n",
    "\n",
    "If we know the function that the loss is computed from and it is differentiable, then we can calculate the derivative of the loss with respect to our model parameters by hand, and iteratively move each parameter in the direction of the opposite sign. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing gradient descent from scratch\n",
    "\n",
    "Below is a derivation for computing the rate of change (gradient) of the loss with respect to our model parameters when using a linear model and the mean squared error loss function.\n",
    "![title](images/NN1_single_grad_calc.jpg)\n",
    "\n",
    "Complete the class below to return the derivative of our loss w.r.t the weight and bias by implementing the above equations in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearHypothesis:\n",
    "    def __init__(self): \n",
    "        self.w = np.random.randn() ## weight\n",
    "        self.b = np.random.randn() ## bias\n",
    "    \n",
    "    def __call__(self, X): ## how do we calculate output from an input in our model?\n",
    "        y_hat = self.w*X + self.b ## make linear prediction\n",
    "        return y_hat\n",
    "    \n",
    "    def update_params(self, new_w, new_b):\n",
    "        self.w = new_w ## set this instance's w to the new w\n",
    "        self.b = new_b ## set this instance's b to the new b\n",
    "        \n",
    "    def calc_deriv(self, X, y_hat, labels):\n",
    "        m = len(Y) ## m = number of examples\n",
    "        diffs = y_hat - labels ## calculate errors\n",
    "        dLdw = 2*np.array(np.sum(diffs*X) / m) ## calculate derivative of loss with respect to weights\n",
    "        dLdb = 2*np.array(np.sum(diffs)/m) ## calculate derivative of loss with respect to bias\n",
    "        return dLdw, dLdb ## return rate of change of loss wrt w and wrt b\n",
    "    \n",
    "H = LinearHypothesis() ## initialise our model\n",
    "y_hat = H(X) ## make prediction\n",
    "dLdw, dLdb = H.calc_deriv(X, y_hat, Y) ## calculate gradient of current loss with respect to model parameters\n",
    "\n",
    "print(dLdw, dLdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can complete the derivatives, complete the train function below to iteratively improve our parameter estimates to minimize the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.1\n",
    "H = LinearHypothesis()\n",
    "\n",
    "def plot_loss(losses):\n",
    "    plt.figure() ## make a figure\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.plot(losses) ## plot costs\n",
    "\n",
    "def train(num_epochs, X, Y, H, L, plot_cost_curve=False):\n",
    "    all_costs = [] ## initialise empty list of costs to plot later\n",
    "    for e in range(num_epochs): ## for this many complete runs through the dataset\n",
    "        y_hat = H(X) ## make predictions\n",
    "        cost = L(y_hat, Y) ## compute loss \n",
    "        dLdw, dLdb = H.calc_deriv(X, y_hat, Y) ## calculate gradient of current loss with respect to model parameters\n",
    "        new_w = H.w - learning_rate * dLdw ## compute new model weight using gradient descent update rule\n",
    "        new_b = H.b - learning_rate * dLdb ## compute new model bias using gradient descent update rule\n",
    "        H.update_params(new_w, new_b) ## update model weight and bias\n",
    "        all_costs.append(cost) ## add cost for this batch of examples to the list of costs (for plotting)\n",
    "    if plot_cost_curve: ## plot stuff\n",
    "       plot_loss(all_costs)\n",
    "    print('Final cost:', cost)\n",
    "    print('Weight values:', H.w)\n",
    "    print('Bias values:', H.b)\n",
    "\n",
    "train(num_epochs, X, Y, H, L, plot_cost_curve=True) # train model and plot cost curve\n",
    "visualise_regression_data(X, Y, H(X)) # plot predictions and true data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why gradient based optimisation?\n",
    "We previously mentioned shortcomings of random search:\n",
    "- our search region not containing an optimal parameterisation for our model\n",
    "- exponential increase in runtime with each additional parameter\n",
    "\n",
    "But beyond these, an advantage of using gradient based optimisation is that it follows a **heuristic** - an indication of how to improve. The heuristic is the gradient, which indicates what might be a good way to improve the weights. \n",
    "Grid and random search are not heuristic search methods. Each time they try a new parameterisation, they don't get any more information about where might be a good next parameterisation. Instead, they simply try a new set of values by choosing totally randomly (random search) or by picking a predetermined value at the next point on the grid (grid search).\n",
    "\n",
    "By using gradient descent, which follows a heuristic indication of where to try next (down the hill), our model can converge in much less iterations compared to grid or random search. If we firstly initialise our parameters near to the optima on the loss surface, gradient descent might only need a few updates, whereas grid or random searches will always take the same amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why should we not pass the whole dataset through the model for each update?\n",
    "We know that to perform gradient based optimisation we need to pass inputs through the model (forward pass), and then compute the loss and find how it changes with respect to each of our model's parameters (backward pass). Modern datasets can be absolutely huge. This means that the forward pass can take a long time, as the function which our model represents has to be applied to each and every input given to it for a forward pass.\n",
    "\n",
    "Passing the full dataset through the model at each pass is called **full batch gradient descent**.\n",
    "\n",
    "### Why not just pass a single datapoint to the model for each update?\n",
    "We want our model to perform well on all examples, not just single examples. So we want to compute the loss and associated gradients over several examples to get an average gradient that should lead to better performance across any example, not just this specific one. If we only pass a single example through, the gradient won't be based on a representative sample.\n",
    "\n",
    "Passing single examples through the model at each pass is called **stochastic gradient descent**.\n",
    "\n",
    "## Mini-batch gradient descent\n",
    "The modern way to do training is neither full-batch (whole dataset) or fully stochastic (single datapoint). Instead we use mini-batch training, where we sample several (but not all) datapoints to compute a sample of the gradient, which we then use to update the model. Most optimisation algorithms converge much faster if they are allowed to rapidly compute approximate gradients rather than slowly compute exact gradients. The size of the mini-batch is called the **batch size**. Mini-batches are commonly incorrectly referred to as batches, but it's not that deep. \n",
    "\n",
    "We will experiment with the effect of batch size on the training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from random import shuffle\n",
    "\n",
    "def create_batches(dataset, batch_size=4):\n",
    "    shuffle(dataset) # shuffle the dataset. why?\n",
    "    idx = 0 # initialise starting point in dataset (index of first example to be put into the next batch)\n",
    "    batches = []\n",
    "    while idx < len(dataset): # while starting point index is less than the length of the dataset \n",
    "        if idx + batch_size < len(dataset): # if enough examples remain to make a whole batch\n",
    "            batch = dataset[idx: idx + batch_size] # make a batch from those examples \n",
    "        else: # otherwise\n",
    "            batch = dataset[idx:] # take however many examples remain (less than batch size)\n",
    "        batches.append(batch) # add this batch to the list of batches\n",
    "        idx += batch_size # increment the starting point for the next batch\n",
    "    batches = [np.array(list(zip(*b))) for b in batches] # unzip the batches into lists of inputs and outputs so batch = [all_inputs, all_outputs] rather than batch = [(input_1, output_1), ..., (input_batch_size, output_batch_size)]\n",
    "    return batches\n",
    "\n",
    "dataset = list(zip(X, Y))\n",
    "data_loader = create_batches(dataset, batch_size=4)\n",
    "print(data_loader)\n",
    "for idx, batch in enumerate(data_loader):\n",
    "    print(f'Batch {idx}:')\n",
    "    print(batch)\n",
    "print('data loader length', len(data_loader)) # should be m / batch_size rounded up\n",
    "print('batch size:', batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's update our training function so that it performs mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "H = LinearHypothesis()\n",
    "m = 10000\n",
    "num_updates = 10 * m\n",
    "# X, Y = sample_linear_data(m)\n",
    "dataset = list(zip(X, Y))\n",
    "\n",
    "def train(num_updates, data_loader, H, L, plot_cost_curve=False, plot_h=False):\n",
    "    costs = [] # initialise empty list of costs to plot later\n",
    "    update_idx = 0\n",
    "    inference_times = []\n",
    "    update_times = []\n",
    "    while update_idx < num_updates: # for this many complete runs through the dataset\n",
    "        batch_costs = []\n",
    "        for x, y in data_loader:\n",
    "            inference_start = time() # get time at start of inference\n",
    "            y_hat = H(x) # make predictions\n",
    "            inference_times.append(time() - inference_start) # add duration of inference\n",
    "            cost = L(y_hat, y) # compute loss \n",
    "            update_start = time()\n",
    "            dLdw, dLdb = H.calc_deriv(x, y_hat, y) # calculate gradient of current loss with respect to model parameters\n",
    "            new_w = H.w - learning_rate * dLdw # compute new model weight using gradient descent update rule\n",
    "            new_b = H.b - learning_rate * dLdb # compute new model bias using gradient descent update rule\n",
    "            H.update_params(new_w, new_b) # update model weight and bias\n",
    "            update_times.append(time() - update_start)\n",
    "            update_idx += 1\n",
    "            batch_costs.append(cost)\n",
    "            #prop_complete = round((update_idx / num_updates) * 100)     \n",
    "            #print('\\r' + [\"|\", \"/\", \"-\", \"\\\\\"][update_idx % 4], end='')\n",
    "            #print(f'\\r[{prop_complete * \"=\" + (0 - prop_complete) * \"-\"}]', end='')\n",
    "        costs.append(np.mean(batch_costs)) # add cost for this batch of examples to the list of costs (for plotting)\n",
    "    if plot_cost_curve: # plot stuff\n",
    "        plt.figure() # make a figure\n",
    "        plt.ylabel('Cost')\n",
    "        plt.xlabel('Update idx')\n",
    "        plt.plot(costs) # plot costs\n",
    "        plt.show()\n",
    "    if plot_h:\n",
    "        plot_h_vs_y(X, H(X), Y)\n",
    "    print(f'Average inference (prediction) time: {np.mean(inference_times)*1000:.3f} milliseconds')\n",
    "    print(f'Average weight update time: {np.mean(update_times)*1000:.3f} milliseconds')\n",
    "    print('Final cost:', cost)\n",
    "#     print('Weight values:', H.w)\n",
    "#     print('Bias values:', H.b)\n",
    "    print()\n",
    "    \n",
    "\n",
    "print('Full batch training')\n",
    "full_batch_data_loader = create_batches(dataset, batch_size=len(dataset))\n",
    "train(num_updates, full_batch_data_loader, H, L, plot_cost_curve=False)\n",
    "\n",
    "print('Stochastic training')\n",
    "stochastic_data_loader = create_batches(dataset, batch_size=1)\n",
    "train(num_updates, stochastic_data_loader, H, L, plot_cost_curve=False)\n",
    "\n",
    "print('Mini-batch training')\n",
    "mini_batch_data_loader = create_batches(dataset, batch_size=32)\n",
    "train(num_updates, mini_batch_data_loader, H, L, plot_cost_curve=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that stochastic and mini-batch training perform inference (making predictions) >3x faster and make updates 2.5x faster than full batch training. For larger datasets or inputs, these differences would be exaggerated even further. This is because the model has to pass the whole dataset forward to make a prediction and then compute the average gradient from every single one of those values to compute the weight and bias updates.\n",
    "\n",
    "For a larger dataset with more complex example features and/or labels, stochastic gradient descent may not converge, because single examples may rarely produce a gradient that is representative of an update that would reduce the error for all examples, rather than just this example.\n",
    "\n",
    "## Summary\n",
    "- gradient based optimisation is an optimisation technique based on iteratively adjusting the parameters of a model in the direction that will decrease the objective function\n",
    "- stochastic gradient descent is a robust and scalable way to train parametric models\n",
    "    - optimisation time scales linearly with the number of parameters\n",
    "- random search and grid search are far inferior to SGD & other gradient based optimisation techniques. Please don't use them again.\n",
    "- full batch training updates the parameters based on the gradient of the loss for all samples with respect to the model parameters\n",
    "- stochastic training updates the parameters based on the gradient of the loss for a single sample with respect to the model parameters\n",
    "- splitting our datasets into mini-batches can improve training speed\n",
    "    - less examples to process per update\n",
    "    - each update is based on a representative sample of the gradient to follow\n",
    "\n",
    "## Next steps\n",
    "- [Multivariate regression and feature normalisation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
